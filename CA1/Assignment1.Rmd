---
title: "Assignment I"
subtitle: "Analysis of 2 x 2 Tables"
author: "Silpa Soni Nallacheruvu (19980824-5287) Hernan Aldana (20000526-4999)"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(MASS)
library(epitools)
library(kableExtra)
```

---


# Exercise 1:1

This report analyzes opinions on legal abortion among men and women based on survey data. The analysis includes hypothesis testing, calculation of odds and risk ratios, and comparison of methods. The goal is to understand the association between gender and opinion on legal abortion.

```{r echo=FALSE, fig.align='center'}

tab1 <- matrix(
  c(309, 191, 319, 281), # Data in row-major order
  nrow = 2,                 # Two rows: Men and Women
  byrow = TRUE,             # Fill matrix by rows
  dimnames = list(
    gender = c("Women", "Men"),        # Row names
    admission = c("In favor", "Against") # Column names
  )
)

# Display the table
knitr::kable(
  tab1,
  caption = "Opinions on legal abortion"
) 

```


## Question 1: Percentage in Favor and Against Legal Abortion by Gender

### Approach: 

The percentages for being “in favor” and “against” legal abortion for men and women were calculated using the following formulas:

- Percentage (In Favor):

${\text{Percentage (In Favor)} = \frac{\text{Count (In Favor) of the Gender}}{\text{Total Count of the Gender}} \times 100}$

- Percentage (Against):

${\text{Percentage (Against)} = \frac{\text{Count (Against) of the Gender}}{\text{Total Count of the Gender}} \times 100}$

### Calculations: 

For Women: 

- In Favor:   ${\text{Percentage (In Favor) for Women} = \frac{309}{500} \times 100 = 61.8\%}$

- Against:     ${\text{Percentage (Against) for Women} = \frac{191}{500} \times 100 = 38.2\%}$

For Men:

- In Favor:   ${\text{Percentage (In Favor) for Men} = \frac{319}{600} \times 100 = 53.2\%}$

- Against:     ${\text{Percentage (Against) for Men} = \frac{281}{600} \times 100 = 46.8\%}$

### R Output: 

```{r percentage-summary, echo=FALSE, fig.align='center'}
# Calculate percentages
women_in_favor <- 309
women_total <- 500
men_in_favor <- 319
men_total <- 600
women_against <- women_total - women_in_favor
men_against <- men_total - men_in_favor

# Percentages
women_in_favor_pct <- round((women_in_favor / women_total) * 100, 1)
women_against_pct <- round((women_against / women_total) * 100, 1)
men_in_favor_pct <- round((men_in_favor / men_total) * 100, 1)
men_against_pct <- round((men_against / men_total) * 100, 1)

# Create summary table
summary_table <- data.frame(
  Gender = c("Women", "Men"),
  `Percentage In Favor` = c(women_in_favor_pct, men_in_favor_pct),
  `Percentage Against` = c(women_against_pct, men_against_pct)
)

kable(summary_table, col.names = c("Gender", "% In Favor", "% Against"),
      caption = "Percentage In Favor and Against Legal Abortion by Gender", align = c("l", "c", "c")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```


### Analysis: 

- Women: 61.8% are in favor, while 38.2% are against legal abortion.
- Men: 53.2% are in favor, while 46.8% are against legal abortion.


## Question 2: Hypothesis Testing (Pearson’s (X^2) and Likelihood Ratio (G^2))

### Approach: 

Test for independence between gender and opinions using:

- Pearson’s Chi-Squared Test  

- Likelihood Ratio Test

#### 1. Define Hypotheses: 

- Null Hypothesis (${H_0}$): There is no difference in opinions between men and
women on legal abortion.

- Alternative Hypothesis (${H_A}$): There is a difference in opinions between
men and women on legal abortion.

#### 2. Expected Counts: 

Under ${H_0}$, expected counts are calculated using: 

${E_{ij} = \frac{\text{i-th Row Total} \times \text{j-th Column Total}}{\text{Grand Total}}}$

#### 3. Pearson’s Chi-Squared Statistic:

The formula for Pearson’s Chi-Squared Statistic (${X^2}$) is: 

${X^2 = \sum_{i=1}^{r} \sum_{j=1}^{c} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}}$

#### 4. Likelihood Ratio Statistic: 

The formula for Likelihood Ratio Statistic (${G^2}$) is: 

${G^2 = 2 \sum_{i=1}^{r} \sum_{j=1}^{c} O_{ij} \log\left(\frac{O_{ij}}{E_{ij}}\right)}$

where:  

  - $O_{ij}$: Observed counts of (i,j) cell  

  - $E_{ij}$: Expected counts of (i,j) cell 
  
  - $r$: Total number of rows 

  - $c$: Total number of columns

The degrees of freedom are calculated for both statistics as $df=(r-1)(c-1)$ 

### Calculations: 

Expected counts under $H_0$ are calculated as:  

${E_{ij} = \frac{(\text{Row Total}_i) \times (\text{Column Total}_j)}{\text{Grand Total}}}$

For Women: 

- In Favor:  ${E_{11} = \frac{R_1 \times C_1}{N} = \frac{500 \times 628}{1100} \approx 285.45}$  

- Against:   ${E_{12} = \frac{R_1 \times C_2}{N} = \frac{500 \times 472}{1100} \approx 214.55}$  


For Men:

- In Favor:  ${E_{21} = \frac{R_2 \times C_1}{N} = \frac{600 \times 628}{1100} \approx 342.55}$. 

- Against:  ${E_{22} = \frac{R_2 \times C_2}{N} = \frac{600 \times 472}{1100} \approx 257.45}$. 

Calculating the Pearson's Chi-Squared Test Statistic:  

${X^2} = \frac{(309 - 285.45)^2}{285.45} + \frac{(191 - 214.55)^2}{214.55} + \frac{(319 - 342.55)^2}{342.55} + \frac{(281 - 257.45)^2}{257.45} =  1.94 + 2.58 + 1.62 + 2.15 = 8.29$

Calculating the Likelihood Ratio Test Statistic:

${G^2} = 2 \times [ 309 \times \log\left(\frac{309}{285.45}\right) + 191 \times \log\left(\frac{191}{214.55}\right) + 319 \times \log\left(\frac{319}{342.55}\right) + 281 \times \log\left(\frac{281}{257.45}\right) ] = 48.99 - 44.41 - 45.44 + 49.19 = 8.33$


### R Output: 

```{r hypothesis-testing, echo=FALSE, fig.align='center'}
# Observed counts
observed <- matrix(c(309, 191, 319, 281), nrow = 2, byrow = TRUE)
rownames(observed) <- c("Women", "Men")
colnames(observed) <- c("In Favor", "Against")

# Totals
row_totals <- rowSums(observed)
col_totals <- colSums(observed)
grand_total <- sum(observed)

# Expected counts
expected <- outer(row_totals, col_totals) / grand_total

# Pearson's X^2
X2 <- sum((observed - expected)^2 / expected)

# Likelihood Ratio G^2
G2 <- 2 * sum(observed * log(observed / expected))

# Degrees of freedom
df <- (nrow(observed) - 1) * (ncol(observed) - 1)

# P-values
p_value_X2 <- pchisq(X2, df = df, lower.tail = FALSE)
p_value_G2 <- pchisq(G2, df = df, lower.tail = FALSE)

# Results
results <- data.frame(
  Statistic = c("Pearson's X^2", "Likelihood Ratio G^2"),
  Value = c(X2, G2),
  `P-value` = c(p_value_X2, p_value_G2)
)
kable(results, caption = "Hypothesis Testing Results", align = c("l", "c", "c")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

### Conclusion: 

- Both the ${X^2}$ and ${G^2}$ statistics yield small p-values, much lesser than 0.05 as the significance level to test our null hypothesis ${H_0}$.
- Hence, we reject the null hypothesis ${H_0}$, which indicates that there is a significant difference in opinions on legal abortion between men and women.

## Question 3: Odds Ratio and 95% Confidence Interval

## Approach:

The odds ratio (OR) is a measure used to quantify the strength of association 
between two categorical variables. 

- For Women: Odds in Favor: ${\text{Odds (Women)} = \frac{\text{In Favor (Women)}}{\text{Against (Women)}}}$

- For Men: Odds in Favor: ${\text{Odds (Men)} = \frac{\text{In Favor (Men)}}{\text{Against (Men)}}}$

#### Odds Ratio (OR):

The odds ratio compares the odds of being “in favor” for men to that for women:

${\text{OR} = \frac{\text{Odds (Men)}}{\text{Odds (Women)}}}$

### Calculations: 

- For Women: ${\text{Odds (Women)} = \frac{309}{191} = 1.6178}$

- For Men: ${\text{Odds (Men)} = \frac{319}{281} = 1.1352}$

- Odds Ratio for Men: ${\text{OR} = \frac{1.1352}{1.6178} = 0.7017}$

### R Output: 

```{r odds-ratio, echo=FALSE, fig.align='center'}
# Odds calculation
odds_women <- women_in_favor / women_against
odds_men <- men_in_favor / men_against
# Odds ratio
odds_ratio <- odds_men / odds_women
# Results
results <- data.frame(
  Odds = c("Odds Women", "Odds Men", "Odds Ratio"),
  Value = c(odds_women, odds_men, odds_ratio)
)
kable(results, caption = "Odds Ratio Results", align = c("l", "c", "c")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

Alternative Odds Ratios can be formulated depending on the conditioning variable:

Odds ratio of being a man vs. a woman among those “in favor”:

${\text{OR} = \frac{\text{Men In Favor / Women In Favor}}{\text{Men Against / Women Against}}}$

Odds ratio of being against legal abortion for men vs. women:

${\text{OR} = \frac{\text{Men Against / Women Against}}{\text{Men In Favor / Women In Favor}}}$

Each odds ratio provides different insights based on the event being studied and 
the conditioning variable.

### Confidence Interval: 

To compute the 95% confidence interval for the odds ratio, let us use the 
logarithm of odds ratio for a more accurate result and then apply the delta method 
to get the confidence interval of odds ratio from the confidence interval 
of logarithm of odds ratio.

### Calculations: 

- Standard Error of ${\log(\text{OR})}$: ${\text{SE}_{OR} = \sqrt{\frac{1}{O_{11}} + \frac{1}{O_{12}} + \frac{1}{O_{21}} + \frac{1}{O_{22}}} = \sqrt{\frac{1}{309} + \frac{1}{191} + \frac{1}{319} + \frac{1}{281}} = 0.1225}$

- 95% confidence interval for ${\log(\text{OR})}$: ${\log(\text{OR}) \pm z_{0.975} \times \text{SE}_{OR}}$

- Then, we get the confidence interval for the $\text{OR}$ by exponentiating the above bounds.

### R Output: 

```{r echo=FALSE, fig.align='center'}
# Log odds ratio and standard error
log_odds_ratio <- log(odds_ratio)
se_log_odds <- sqrt(sum(1 / observed))

# Confidence interval
z <- qnorm(0.975)
ci_lower <- exp(log_odds_ratio - z * se_log_odds)
ci_upper <- exp(log_odds_ratio + z * se_log_odds)
# Results
odds_results <- data.frame(
  Measure = c("Odds Ratio", "95% CI Lower", "95% CI Upper"),
  Value = c(odds_ratio, ci_lower, ci_upper)
)
kable(odds_results, caption = "Odds Ratio and Confidence Interval", align = c("l", "c")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

###  Interpretation

- The estimated odds ratio is 0.7015 indicating that the odds of men supporting legal abortion are about 70.2% of the odds of women supporting it. 
- The 95% confidence interval (0.556, 0.886) does not include 1, indicating a statistically significant difference in the opinions.

## Question 4: Risk Ratio and 95% Confidence Interval

### Approach:

The risk ratio (also called relative risk, RR) quantifies the likelihood of an event occurring in one group relative to another group. Here, the risk refers to the probability of being “in favor” of legal abortion.

- Risk for Women: ${\text{Risk (Women)} = \frac{\text{Number of Women In Favor}}{\text{Total (Women)}}}$

- Risk for Men: ${\text{Risk (Men)} = \frac{\text{Number of Men In Favor}}{\text{Total (Men)}}}$

#### Risk Ratio (Relative Risk):

The risk ratio (RR) compares the risk of being “in favor” for men to that for women:  

${\text{RR} = \frac{\text{Risk (Men)}}{\text{Risk (Women)}}}$

### Calculations: 

- For Women: ${\text{Risk (Women)} = \frac{309}{500} = 0.618}$

- For Men: ${\text{Risk (Men)} = \frac{319}{600} \approx 0.5316}$

- Risk Ratio for Men: ${\text{RR} = \frac{0.5316}{0.618} \approx 0.8602}$

### R Output: 

```{r risk-ratio, echo=FALSE, fig.align='center'}
# Risk calculation
risk_women <- women_in_favor / women_total
risk_men <- men_in_favor / men_total

# Risk ratio
risk_ratio <- risk_men / risk_women
results <- data.frame(
  Risk = c("Risk Women", "Risk Men", "Risk Ratio"),
  Value = c(risk_women, risk_men, risk_ratio)
)
kable(results, caption = "Risk Ratio Results", align = c("l", "c", "c")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

### Analysis: 

- This value indicates that men are about 86.1% as likely as women to be 
“in favor” of legal abortion.

#### Confidence Interval:

To compute the 95% confidence interval for the risk ratio, let us use the 
logarithm of risk ratio for a more accurate result, similar to odds ratio and 
then apply the delta method to get the confidence interval of risk ratio from 
the confidence interval of logarithm of risk ratio.

### Calculations: 

- Standard error of $log(RR)$: ${\text{SE}_{RR} = \sqrt{\frac{1}{\text{In Favor (Men)}} - \frac{1}{\text{Total (Men)}} + \frac{1}{\text{In Favor (Women)}} - \frac{1}{\text{Total (Women)}}}}$

${= \sqrt{\frac{1}{319} - \frac{1}{600} + \frac{1}{309} - \frac{1}{500}} \approx 0.1}$

- 95% Confidence Interval for $log(RR)$: ${\log(\text{RR}) \pm z_{0.975} \times \text{SE}_{RR}}$

- Then, we have to get the confidence interval for the $\text{RR}$ by exponentiating the above bounds.

### R Output: 

```{r echo=FALSE, fig.align='center'}
# Log risk ratio and standard error
log_risk_ratio <- log(risk_ratio)
se_log_risk <- sqrt(1 / women_in_favor - 1 / women_total + 1 / men_in_favor - 1 / men_total)

# Confidence interval
ci_lower_rr <- exp(log_risk_ratio - z * se_log_risk)
ci_upper_rr <- exp(log_risk_ratio + z * se_log_risk)

# Results
risk_results <- data.frame(
  Measure = c("Risk Ratio", "95% CI Lower", "95% CI Upper"),
  Value = c(risk_ratio, ci_lower_rr, ci_upper_rr)
)
kable(risk_results, caption = "Risk Ratio and Confidence Interval", align = c("l", "c")) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

### Interpretation

- The estimated risk ratio is 0.861 indicating that men are about 86.1% as 
likely as women to be “in favor” of legal abortion. 
- The 95% confidence interval (0.756, 0.980) does not include 1,, indicating a statistically significant difference in the opinions.

### Comparison with Odds Ratio

- **Odds Ratio:**  highlights the relative change of odds, previously calculated as 0.7015, quantifying the odds of men being “in favor” compared to women.
            
- **Risk Ratio:** provides a more intuitive interpretation, previously calculated as 0.861, quantifying the relative probability men of being “in favor” compared to women.

- Both the ratios indicate that the women are significantly more likely to support legal abortion compared 
to men.


## Question 5: Verification of Previous Calculations

### Approach: 

Verify the calculations for percentages, hypothesis testing, odds ratio, and risk ratio from Questions 1–4 using built-in R functions. The results are compared with the manual calculations presented earlier.

#### 1. Generate Frequency Table and Calculate Row Percentages

```{r echo=FALSE}
# Prepare the data and calculate row percentages
tab1 <- as.table(rbind(c(309, 191), c(319, 281)))
dimnames(tab1) <- list(
  Gender = c("Women", "Men"),
  Opinion = c("Favor", "Against")
)

# Add margins
tab1_with_totals <- addmargins(tab1)

# Calculate row percentages
row_percentages <- addmargins(prop.table(tab1, 1), 2)

# Create summary tables
tab1_kable <- kable(tab1_with_totals, caption = "Counts of Opinions by Gender", align = "c") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))

row_percentages_kable <- kable(row_percentages, caption = "Row Percentages of Opinions by Gender", align = "c") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))

# Display tables
tab1_kable
row_percentages_kable
```

#### Comparison:

The row percentages are verified, and the results align with the previously calculated values.

#### 2. Calculate X2, G2 and p-values

```{r echo=FALSE}

# Perform the Chi-squared test
chi_squared_result <- chisq.test(tab1, correct = FALSE)

# Perform the log-likelihood ratio test
log_likelihood_ratio <- loglm(~ Gender + Opinion, tab1)

# Organize Chi-squared test results into a table
chi_squared_summary <- data.frame(
  Statistic = "Chi-squared (X²)",
  Value = round(chi_squared_result$statistic, 3),
  Degrees_of_Freedom = chi_squared_result$parameter,
  P_value = signif(chi_squared_result$p.value, 3)
)

# Display the Chi-squared results
chi_squared_table <- kable(
  chi_squared_summary,
  caption = "Chi-squared Test Results",
  align = c("l", "c", "c", "c")
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))

# Organize log-likelihood ratio results into a table
log_likelihood_summary <- data.frame(
  Statistic = "Log-likelihood Ratio (G²)",
  Value = round(log_likelihood_ratio$lrt, 3),
  Degrees_of_Freedom = log_likelihood_ratio$df,
  P_value = signif(1 - pchisq(log_likelihood_ratio$lrt, log_likelihood_ratio$df), 3)
)

# Display the log-likelihood ratio results
log_likelihood_table <- kable(
  log_likelihood_summary,
  caption = "Log-likelihood Ratio Test Results",
  align = c("l", "c", "c", "c")
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))

# Print both tables
chi_squared_table
log_likelihood_table
```

##### Comparison: 
- (X^2) statistic, degrees of freedom, and p-value displayed, matching the previous calculations.
- (G^2) statistic and p-value are also displayed, confirming the earlier results.

#### 3. Calculate Odds Ratio and Confidence Interval

- odds of men to women:
 
```{r echo=FALSE}
# To obtain the intended odds/risk ratio, you may need to reverse the rows or columns:
odds_ratio_col <- oddsratio(tab1, method = "wald", rev="col")
# Extract results from odds ratio
odds_result <- data.frame(
  Measure = "Odds Ratio",
  Value = round(odds_ratio_col$measure[2, 1], 3),
  `95% CI Lower` = round(odds_ratio_col$measure[2, 2], 3),
  `95% CI Upper` = round(odds_ratio_col$measure[2, 3], 3)
)
kable(
  odds_result,
  col.names = c("Measure", "Value", "95% CI Lower", "95% CI Upper"),
  caption = "Odds Ratio with Confidence Intervals",
  align = c("l", "c", "c", "c")
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

#### Comparison:

The odds ratio of men to women and its confidence interval are verified, and the results align with the earlier values when the columns are reversed from the given table.


#### 4. Calculate Risk Ratio and Confidence Interval

- risk of men to women:

```{r echo=FALSE}
# Check alternative row/column reversals to match the intended risk ratio
risk_ratio_col <- riskratio(tab1, rev = "col")
risk_result <- data.frame(
  Measure = "Risk Ratio",
  Value = round(risk_ratio_col$measure[2, 1], 3),
  `95% CI Lower` = round(risk_ratio_col$measure[2, 2], 3),
  `95% CI Upper` = round(risk_ratio_col$measure[2, 3], 3)
)
# Display the table
kable(
  risk_result,
  col.names = c("Measure", "Value", "95% CI Lower", "95% CI Upper"),
  caption = "Odds Ratio and Risk Ratio with Confidence Intervals",
  align = c("l", "c", "c", "c")
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))

```

#### Comparison:

The risk ratio of men to women and its confidence interval are verified, and the results align with the earlier values when the columns are reversed from the given table.


## Conclusion:

This analysis highlights significant gender differences in opinions on legal abortion. Both hypothesis testing and measures of association confirm that women are more likely to support legal abortion than men. These findings underscore the importance of considering gender perspectives in public policy discussions.

---

\newpage

# Exercise 1:2

We are analyzing the admissions data from the University of California, Berkeley, following the 2x2 contingency table:

```{r echo=FALSE}

tab2 <- matrix(
  c(1198, 1493, 557, 1278), # Data in row-major order
  nrow = 2,                 # Two rows: Men and Women
  byrow = TRUE,             # Fill matrix by rows
  dimnames = list(
    gender = c("Men", "Women"),        # Row names
    admission = c("Admitted", "Not Admitted") # Column names
  )
)

# Display the table
knitr::kable(
  tab2,
  caption = "Summary Table"
)
```

## Question 1:

### Approach: 

Our goal is to perform the following analyses:

  1. Calculate the percentages of admitted and not admitted applicants separately.  
  
  2. Test for independence between gender and admission using:
  
      - Pearson’s Chi-Squared Test
      - Likelihood Ratio Test
      
  3. Calculate the odds ratio and its 95% confidence interval.
  
  4. Calculate the risk ratio and its 95% confidence interval.  

**1. Calculating Percentages:**

  **For Men:**

  - Total men: $n_{\text{Men}} = 2691$  
  
  - Admitted men: $a_{\text{Men}} = 1198$  
  
  - Not admitted men: $n_{\text{Men}} - a_{\text{Men}} = 1493$  

**Percentages For Men:**

$\text{Percentage Admitted (Men)} = \left( \frac{1198}{2691} \right) \times 100\% \approx 44.53\%$  

$\text{Percentage Not Admitted (Men)} = 100\% - 44.53\% = 55.47\%$

**For women:**

  - Total women: $n_{\text{Women}} = 1835$  

  - Admitted women: $a_{\text{Women}} = 557$  

  - Not admitted women: $n_{\text{Women}} - a_{\text{Women}} = 1278$  
  
**Percentages For Women:**

$\text{Percentage Admitted (Women)} = \left( \frac{557}{1835} \right) \times 100\% \approx 30.35\%$  

$\text{Percentage Not Admitted (Women)} = 100\% - 30.35\% = 69.65\%$  

```{r echo=FALSE}
# Admissions data (Berkeley)
tab3 <- data.frame(
  Gender = c("Men", "Women"),
  `% Admitted` = c(44.53, 30.35),
  `% Not Admitted` = c(55.47, 69.65)
)
# Display the table
knitr::kable(
  tab3,
  col.names = c("Gender", "% Admitted", "% Not Admitted"),
  caption = "Summary Table",
  align = c("l", "c", "c")
)
```
**2. Testing for Independence:**

Null hypothesis ($H_0$): Gender and admission are independent.  

Alternative hypothesis ($H_1$): There is an association between gender and admission Status.

Expected counts under $H_0$ are calculated as:  

$E_{ij} = \frac{(\text{Row Total}_i) \times (\text{Column Total}_j)}{\text{Grand Total}}$

  1. Men Admitted:  

      $E_{11} = \frac{R_1 \times C_1}{N} = \frac{2691 \times 1755}{4526} \approx 1043.46$  

  2. Men not Admitted:  

      $E_{12} = \frac{R_1 \times C_2}{N} = \frac{2691 \times 2771}{4526} \approx 1647.54$  

  3. Women Admitted:  

      $E_{21} = \frac{R_2 \times C_1}{N} = \frac{1835 \times 1755}{4526} \approx 711.54$. 

  4. Women not Admitted:  

      $E_{22} = \frac{R_2 \times C_2}{N} = \frac{1835 \times 2771}{4526} \approx 1123.46$. 

Calculating the Pearson's Chi-Squared Test Statistic:  

$X^2 = \sum_{i=1}^{2} \sum_{j=1}^{2} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}$  

Calculating the Likelihood Ratio Test Statistic:  

$G^2 = 2 \sum_{i=1}^{2} \sum_{j=1}^{2} O_{ij} \ln\left( \frac{O_{ij}}{E_{ij}} \right)$  

where:  

  - $O_{ij}$: Observed counts  

  - $E_{ij}$: Expected counts  

The degrees of freedom are calculated for both statistics as $df=(r-1)(c-1)$  

**3. Estimating the Odds Ratio:**

  - Odds of Admission for Men:  

    $\text{Odds}_{\text{Men}} = \frac{\text{Admitted Men}}{\text{Not Admitted Men}}$  

  - Odds of Admission for Women:  
  
    $\text{Odds}_{\text{Women}} = \frac{\text{Admitted Women}}{\text{Not Admitted Women}}$ 
    
**Calculating Odds:**
      
  $\text{OR} = \frac{\text{Odds}{\text{Men}}}{\text{Odds}{\text{Women}}}$  

Calculating the Standard Error of $\log(\text{OR})$:

$SE = \sqrt{ \frac{1}{a_{\text{Men}}} + \frac{1}{b_{\text{Men}}} + \frac{1}{a_{\text{Women}}} + \frac{1}{b_{\text{Women}}} }$

The 95% confidence interval for $\log(\text{OR})$ is calculated as:

$\ln(\text{OR}) \pm Z_{0.975} \times SE$

However we still have to get the confidence interval for the odds ratio by exponentiating the bounds.

**4. Estimating the Risk Ratio:**

Calculating Risks (Probabilities):

  - Risk of Admission for Men:  

    $P_{\text{Men}} = \frac{\text{Admitted Men}}{\text{Total Men}}$  

  - Risk of Admission for Women:  

    $P_{\text{Women}} = \frac{\text{Admitted Women}}{\text{Total Women}}$  

**Calculating Risk Ratio (RR):**

$\text{RR} = \frac{P_{\text{Men}}}{P_{\text{Women}}}$  

Calculating the Standard Error of $\log(\text{RR})$:

$SE = \sqrt{ \frac{1 - P_{\text{Men}}}{a_{\text{Men}}} + \frac{1 - P_{\text{Women}}}{a_{\text{Women}}} }$

The 95% confidence interval for $\log(\text{RR})$ is calculated as:

${\ln(\text{RR}) \pm Z_{0.975} \times SE}$

However we still have to get the confidence interval for the risk ratio by exponentiating the bounds.

### Output:

```{r echo=FALSE}
# Perform Chi-Squared Test
chisq_result <- chisq.test(tab2, correct = FALSE)

# Extract results
chisq_summary <- data.frame(
  `Statistic` = round(chisq_result$statistic, 3),
  `Degrees of Freedom` = chisq_result$parameter,
  `P-value` = formatC(chisq_result$p.value, format = "e", digits = 2)
)

# Display the results in a table
kable(
  chisq_summary,
  col.names = c("Chi-Squared Value", "Degrees of Freedom", "P-value"),
  caption = "Chi-Squared Test Results",
  align = c("c", "c", "c")
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

```{r echo=FALSE}
tab2_table <- as.table(tab2)
#tab2_table
# why is this printed here?


# Calculate G2 using loglinear model
loglm_result <- loglm(~ gender + admission, tab2_table)
# Extract key values from the result
loglm_summary <- data.frame(
  Statistic = "G^2 (Likelihood Ratio)",
  Value = loglm_result$lrt,
  Degrees_of_Freedom = loglm_result$df,
  P_Value = signif(1 - pchisq(loglm_result$lrt, df = loglm_result$df), 4)
)

# Present the result in a visually appealing table
kable(
  loglm_summary,
  caption = "Loglinear Model: Likelihood Ratio Test Results",
  col.names = c("Statistic", "Value", "Degrees of Freedom", "P-Value"),
  align = c("l", "c", "c", "c")
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

```{r echo=FALSE}
# Calculate Odds Ratio and Confidence Interval
odds_ratio_result <- oddsratio(tab2, method = "wald", rev = "neither")
# Extract the relevant results
odds_ratio_summary <- data.frame(
  Measure = c("Odds Ratio", "95% CI Lower", "95% CI Upper"),
  Value = c(
    odds_ratio_result$measure[2, 1],  # Odds Ratio
    odds_ratio_result$measure[2, 2], # Lower CI
    odds_ratio_result$measure[2, 3]  # Upper CI
  )
)

# Format the table for better visualization
kable(
  odds_ratio_summary,
  caption = "Odds Ratio and Confidence Interval",
  col.names = c("Measure", "Value"),
  align = c("l", "c")
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

```{r echo=FALSE}
# Calculate Risk Ratio and Confidence Interval
risk_ratio_result <- riskratio(tab2, rev = "both")
# 0.4451/0.3035=1.467
# Extract the relevant results
risk_ratio_summary <- data.frame(
  Measure = c("Risk Ratio", "95% CI Lower", "95% CI Upper"),
  Value = c(
    risk_ratio_result$measure[2, 1],  # Risk Ratio
    risk_ratio_result$measure[2, 2], # Lower CI
    risk_ratio_result$measure[2, 3]  # Upper CI
  )
)

# Format the table for better visualization
kable(
  risk_ratio_summary,
  caption = "Risk Ratio and Confidence Interval",
  col.names = c("Measure", "Value"),
  align = c("l", "c")
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

### Results and Interpretation:

**1. Chi-Squared Test:**

${X^2 = 92.205, p < 2.2e^{-16}}$

The large chi-squared statistic and the small p-value indicate a significant association between gender and admission status. Therefore rejecting the null  hypothesis of independence.

**2. Likelihood Ratio Test:**

${G^2 = 93.98, p < 0.001}$

Similarly as the chi-squared test, the likelihood ratio test also indicates a significant association between gender and admission.

**3. Odds Ratio:**

${\text{OR} = 1.841, 95\% \text{ CI } (1.624, 2.087)}$

According to the odds ratio, men have 1.841 times higher odds of being admitted compared to women. The 95% confidence interval does not include 1, indicating a statistically significant difference in admission odds.

**4. Risk Ratio:**

${\text{RR} = 1.467, 95\% \text{ CI } (1.353, 1.591)}$

Men are 1.467 times more likely to be admitted compared to women. The confidence interval does not include 1, indicating a statistically significant difference in admission risk.

### Conclusion:

There is a statistically significant association between gender and admission status at the University of California, Berkeley during the year of 1975. Men have higher odd and higher probability of admission compared to women. 

## Question 2:

### Approach:

The approach is similar to the previous question. We will analyze what happens if we replace all numbers in the table with one tenth of their original values and perform the same analysis, which we will compare with the previous results.


```{r echo=FALSE, eval=FALSE}
# Function to analyze data
analyze_table <- function(data) {
  # Perform Chi-Squared Test
  chi_result <- chisq.test(data, correct = FALSE)
  
  # Odds Ratio and Risk Ratio
  odds_ratio_result <- oddsratio(data, method = "wald", rev = "neither")
  risk_ratio_result <- riskratio(data, rev = "both")
  
  list(
    "Chi-Squared Test" = chi_result,
    "Likelihood Ratio" = loglm(~gender + admission, data),
    "Odds Ratio" = odds_ratio_result$measure,
    "Risk Ratio" = risk_ratio_result$measure
  )
}

# Original analysis
original_result <- analyze_table(tab2)

# Replace all numbers in the table by one-tenth
tab2_tenth <- round(tab2 / 10, 0)
tenth_result <- analyze_table(tab2_tenth)
one_hundreth_result <- analyze_table(round(tab2 / 100, 0))

# Print results for comparison
list(
  "Original" = original_result,
  "One-Tenth" = tenth_result,
  "One-Hundreth" = one_hundreth_result
)
```

### Results and Interpretation:

#### 1. Chi-Squared Test and Likelihood Ratio Test:

The Chi-Squared  $X^2$ and Likelihood Ratio $G^2$ statistics, as well as their associated p-values, measure the association between gender and admission. The results for the original, one-tenth, and one-hundredth tables are summarized below:

```{r echo=FALSE}
# Create the data frame for the table
result_table <- data.frame(
  Dataset = c("Original", "One-Tenth", "One-Hundredth"),
  Chi2_Statistic = c(92.205, 9.241, 0.775),
  G2_Statistic = c(93.449, 9.364, 0.783),
  p_value = c("< 2.2 × 10^-16", "0.002", "0.379")
)

# Print the table using knitr::kable
knitr::kable(
  result_table,
  col.names = c("Dataset", "X² Statistic", "G² Statistic", "p-value"),
  caption = "Summary of Chi-Squared and Likelihood Ratio Tests",
  align = c("l", "c", "c", "c")
) 
```

As it can be seen, both the Chi-Squared and Likelihood Ratio tests show a dramatic decrease as the table is scaled down, reflecting thus the reduced sample size.
On the other hand, the p-values show a completely different behavior. While the p-value for the original table is extremely small, indicating a significant association between gender and admission, as the table is scaled down, the p-value increases, suggesting that the association cannot be reliably detected with such a small sample size.

#### 2. Odds Ratio:

The odds ratio quantifies the strength of the association between gender and admission. The results for the original, one-tenth, and one-hundredth tables are summarized below:

```{r echo=FALSE}
# Create the data frame for the Odds Ratio table
odds_ratio_table <- data.frame(
  Dataset = c("Original", "One-Tenth", "One-Hundredth"),
  `Odds Ratio (Women)` = c(1.841, 1.841, 1.733),
  `95% Confidence Interval` = c("[1.624, 2.087]", "[1.240, 2.734]", "[0.507, 5.928]")
)

# Print the Odds Ratio table using knitr::kable
knitr::kable(
  odds_ratio_table,
  col.names = c("Dataset", "Odds Ratio (Men/Women)", "95% Confidence Interval"),
  caption = "Odds Ratio for Women Across Datasets",
  align = c("l", "c", "c")
)
```

The odds ratio across the three datasets shows a consistent value, varied only slightly. The confidence interval, however, widens as the sample size decreases, reflecting the increased uncertainty in the estimate. So for the original dataset, the odds ratio is 1.841, with a 95% confidence interval of [1.624, 2.087], which is very narrow, reflecting high precision. On the other hand, for the one-hundredth dataset, the odds ratio is 1.733, with a 95% confidence interval of [0.507, 5.928], which is much wider, reflecting low precision.

#### 3. Risk Ratio:

The risk ratio compares the probability of admission for men and women. The results for the original, one-tenth, and one-hundredth tables are summarized below:

```{r echo=FALSE}
# Create the data frame for the Risk Ratio table
risk_ratio_table <- data.frame(
  Dataset = c("Original", "One-Tenth", "One-Hundredth"), 
  `Risk Ratio (Women)` = c(1.467, 1.466, 1.407),
  `95% Confidence Interval` = c("[1.353, 1.591]", "[1.135, 1.893]", "[0.642, 3.085]")
)

# Print the Risk Ratio table using knitr::kable
knitr::kable(
  risk_ratio_table,
  col.names = c("Dataset", "Risk Ratio (Men/Women)", "95% Confidence Interval"),
  caption = "Risk Ratio for Women Across Datasets",
  align = c("l", "c", "c")
) 
```


The risk ratio across the three datasets shows a consistent value, varied only slightly. The confidence interval, however, widens as the sample size decreases, reflecting the increased uncertainty in the estimate. So for the original dataset, the risk ratio is 1.467, with a 95% confidence interval of [1.353, 1.591], which is very narrow, reflecting high precision. On the other hand, for the one-hundredth dataset, the risk ratio is 1.466, with a 95% confidence interval of [1.135, 1.893], which is comparatively wider, reflecting lower precision. Moreover, for the original dataset, the confidence interval does not include 1, indicating statistical significance. However, for the one-hundredth dataset, the risk ratio is 1.407, with a 95% confidence interval of [0.642, 3.085]. Even though the risk ratio is close to the original and one-tenth risk ratio, the 95% confidence interval is much wider, reflecting the lowest precision. The confidence interval for one-hundredth dataset includes 1, indicating no statistical significance.

### Conclusion:

This question helps us highlight the importance of a sufficiently large sample size for reliabale statistical inference. While relative measures such as odds and risk ratios remain relatively stable across different sample sizes, the precision of the estimates decreases as the sample size decreases. In addition, absolute measures such as $X^2$ and $G^2$ lose significance as the sample size decreases.

## Question 3:

### Approach:

For this question, we will analyze a completely new 2x2 contingency table, such that:

1. The sample odd ratio($\hat{\theta}$) lies within the interval 0.99,1.01

2. The corresponding unkown population odds ratio ($\hat{\theta}$) differs significantly from 1

So in summary, the odd ratio has to be close to 1, and its confidence interval cannot include 1, indicating statistical significance.

The general fomrula for the odds ratio as previously stated is:

$\text{Odds Ratio} (\hat{\theta}) = \frac{(a/c)}{(b/d)} = \frac{a \cdot d}{b \cdot c}$

Where a,b,c,d are the cell counts in the 2x2 table. To achive the requirements we need  $\hat{\theta} \approx 1$ meaning that  $a/c \approx b/d$ or $a \cdot d \approx b \cdot c$.  To ensure  $\theta \neq 1$  we have to use a large sample size to narrow the confidence interval and exclude 1. Finally we have to calculate the confidence interval $\ln(\hat{\theta}) \pm Z_{0.975} \cdot \text{SE}$ and exponentiate the bounds to get the confidence interval for the odds ratio. 


### Output:
```{r echo=FALSE}
# Create the contingency table
tab5 <- matrix(
  c(500000, 500500, 501515, 499090), # Data in row-major order
  nrow = 2,               # Two rows
  byrow = TRUE,           # Fill matrix by rows
  dimnames = list(
    gender = c("Men", "Women"),        # Row names
    admission = c("Admitted", "Not Admitted") # Column names
  )
)
# Display the table
knitr::kable(
  tab5,
  caption = "Summary Table"
) 

# Convert to table
tab_cont <- as.table(tab5)
#tab_cont
```

```{r echo=FALSE}
# Perform likelihood ratio test
lr_result <- loglm(~ gender + admission,tab_cont)

# Extract key components
deviance <- lr_result$deviance
df <- lr_result$df
p_value <- pchisq(deviance, df, lower.tail = FALSE)

# Create a summary table
lr_summary <- data.frame(
  Statistic = "Likelihood ratio (G²)",
  Value = round(deviance, 2),
  Degrees_of_Freedom = df,
  P_Value = format.pval(p_value, digits = 3, eps = 0.001)
)

# Display the table
kable(
  lr_summary,
  col.names = c("Statistic", "Value", "Degrees of Freedom", "P-Value"),
  caption = "Log-Linear Model Summary"
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))

# Perform chi-squared test
chi_result <- chisq.test(tab5, correct = FALSE)
# Extract key components
chi_squared <- chi_result$statistic
df <- chi_result$parameter
p_value <- chi_result$p.value

# Create a summary table
chi_summary <- data.frame(
  Statistic = "Chi-Squared (X²)",
  Value = round(chi_squared, 2),
  Degrees_of_Freedom = df,
  P_Value = format.pval(p_value, digits = 3, eps = 0.001)
)

# Display the table
kable(
  chi_summary,
  col.names = c("Statistic", "Value", "Degrees of Freedom", "P-Value"),
  caption = "Chi-Squared Test Summary"
) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))

# Print results
#cat("Table:\n")
#print(tab_cont) 
# why is it printed three times?
#cat("\nLikelihood Ratio Test:\n")
#print(lr_result)

```
### Results and Interpretation:

**1. Odds Ratio($\hat{\theta}$):**

Using the formula:

 - $\hat{\theta} = \frac{(500,000 \cdot 499,000)}{(500,500 \cdot 501,515)} \approx 0.995$

**2. Confidence Interval:**

 - $[0.990, 0.999]$ 

**3. Statistical tests:**

  - Likelihood Ratio Test: $G^2 = 4.275, p = 0.0387$
  
  - Chi-Squared Test: $X^2 = 4.275, p = 0.0386$
  
### Conclusion:

This exercise illustrates the distinction between statistical significance and practical significance. While the odds ratio is very close to 1, the large sample size ensures a narrow confidence interval, leading to statistical significance. For an accurate report we should focus on effect sizes and their real-world implications rather than just statistical significance with p-values alone.